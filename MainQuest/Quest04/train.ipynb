{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 라이브러리 임포트 및 GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00_flower.npy',\n",
       " '01_crown.npy',\n",
       " '02_heart_beat.npy',\n",
       " '03_firework.npy',\n",
       " '04_bear.npy',\n",
       " '05_cat.npy',\n",
       " '06_son_celebration.npy',\n",
       " '07_heart_on_the_cheek.npy',\n",
       " '08_gun.npy',\n",
       " '09_pipe.npy',\n",
       " '10_tiger.npy',\n",
       " '11_landmarks.npy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = os.listdir('./new_dataset')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./new_dataset/11_landmarks.npy'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'./new_dataset/{dataset[11]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated data shape: (4401, 30, 199)\n",
      "x_data shape: (4401, 30, 198)\n",
      "labels shape: (4401,)\n"
     ]
    }
   ],
   "source": [
    "actions = [\n",
    "    'flower', 'crown', 'heart_beat',\n",
    "    'firework', 'bear', 'cat',\n",
    "    'son_celebration', 'heart_ont_the_cheek', 'gun',\n",
    "    'pipe', 'tiger', 'landmarks'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load(f'./new_dataset/{dataset[0]}'),\n",
    "    np.load(f'./new_dataset/{dataset[1]}'),\n",
    "    np.load(f'./new_dataset/{dataset[2]}'),\n",
    "    np.load(f'./new_dataset/{dataset[3]}'),\n",
    "    np.load(f'./new_dataset/{dataset[4]}'),\n",
    "    np.load(f'./new_dataset/{dataset[5]}'),\n",
    "    np.load(f'./new_dataset/{dataset[6]}'),\n",
    "    np.load(f'./new_dataset/{dataset[7]}'),\n",
    "    np.load(f'./new_dataset/{dataset[8]}'),\n",
    "    np.load(f'./new_dataset/{dataset[9]}'),\n",
    "    np.load(f'./new_dataset/{dataset[10]}'),\n",
    "    np.load(f'./new_dataset/{dataset[11]}'),\n",
    "], axis=0)\n",
    "\n",
    "print(f\"Concatenated data shape: {data.shape}\")\n",
    "\n",
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1] # 첫 번째 프레임의 라벨만 사용 (시퀀스 내 라벨 일관성 가정)\n",
    "print(f\"x_data shape: {x_data.shape}\")\n",
    "print(f\"labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data shape (one-hot encoded): (4401, 12)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "print(f\"y_data shape (one-hot encoded): {y_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 학습/검증 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3960, 30, 198), y_train shape: (3960, 12)\n",
      "x_val shape: (441, 30, 198), y_val shape: (441, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2025)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 64)                67328     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 12)                396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,804\n",
      "Trainable params: 69,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=x_train.shape[1:3]),\n",
    "    Dropout(0.2), # LSTM 출력에 20% 드롭아웃 적용\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2), # Dense 출력에 20% 드롭아웃 적용\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 1.3601 - acc: 0.6367\n",
      "Epoch 1: val_loss improved from inf to 0.37451, saving model to models\\model.h5\n",
      "124/124 [==============================] - 11s 39ms/step - loss: 1.3556 - acc: 0.6381 - val_loss: 0.3745 - val_acc: 0.9660 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.3388 - acc: 0.9378\n",
      "Epoch 2: val_loss improved from 0.37451 to 0.08685, saving model to models\\model.h5\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 0.3359 - acc: 0.9386 - val_loss: 0.0868 - val_acc: 0.9887 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9710\n",
      "Epoch 3: val_loss improved from 0.08685 to 0.02200, saving model to models\\model.h5\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.1502 - acc: 0.9710 - val_loss: 0.0220 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0800 - acc: 0.9881\n",
      "Epoch 4: val_loss improved from 0.02200 to 0.00851, saving model to models\\model.h5\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.0800 - acc: 0.9881 - val_loss: 0.0085 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0561 - acc: 0.9896\n",
      "Epoch 5: val_loss improved from 0.00851 to 0.00463, saving model to models\\model.h5\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.0561 - acc: 0.9896 - val_loss: 0.0046 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0375 - acc: 0.9957\n",
      "Epoch 6: val_loss improved from 0.00463 to 0.00239, saving model to models\\model.h5\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.0375 - acc: 0.9957 - val_loss: 0.0024 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.9970\n",
      "Epoch 7: val_loss improved from 0.00239 to 0.00154, saving model to models\\model.h5\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 0.0261 - acc: 0.9970 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9969\n",
      "Epoch 8: val_loss did not improve from 0.00154\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.0257 - acc: 0.9967 - val_loss: 0.0020 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9959\n",
      "Epoch 9: val_loss improved from 0.00154 to 0.00086, saving model to models\\model.h5\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 0.0235 - acc: 0.9960 - val_loss: 8.6038e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9972\n",
      "Epoch 10: val_loss did not improve from 0.00086\n",
      "124/124 [==============================] - 8s 64ms/step - loss: 0.0169 - acc: 0.9972 - val_loss: 9.3407e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0146 - acc: 0.9970\n",
      "Epoch 11: val_loss improved from 0.00086 to 0.00035, saving model to models\\model.h5\n",
      "124/124 [==============================] - 10s 79ms/step - loss: 0.0146 - acc: 0.9970 - val_loss: 3.4816e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.9980\n",
      "Epoch 12: val_loss did not improve from 0.00035\n",
      "124/124 [==============================] - 6s 46ms/step - loss: 0.0140 - acc: 0.9980 - val_loss: 5.2227e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9977\n",
      "Epoch 13: val_loss improved from 0.00035 to 0.00020, saving model to models\\model.h5\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 0.0137 - acc: 0.9977 - val_loss: 1.9887e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9979\n",
      "Epoch 14: val_loss improved from 0.00020 to 0.00019, saving model to models\\model.h5\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.0137 - acc: 0.9980 - val_loss: 1.9399e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.0116 - acc: 0.9979\n",
      "Epoch 15: val_loss did not improve from 0.00019\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.0115 - acc: 0.9980 - val_loss: 1.9902e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9967\n",
      "Epoch 16: val_loss did not improve from 0.00019\n",
      "124/124 [==============================] - 3s 26ms/step - loss: 0.0136 - acc: 0.9967 - val_loss: 8.6172e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9982\n",
      "Epoch 17: val_loss did not improve from 0.00019\n",
      "124/124 [==============================] - 7s 61ms/step - loss: 0.0129 - acc: 0.9982 - val_loss: 5.0890e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9962\n",
      "Epoch 18: val_loss did not improve from 0.00019\n",
      "124/124 [==============================] - 6s 46ms/step - loss: 0.0172 - acc: 0.9962 - val_loss: 2.7148e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0109 - acc: 0.9980\n",
      "Epoch 19: val_loss improved from 0.00019 to 0.00014, saving model to models\\model.h5\n",
      "124/124 [==============================] - 6s 47ms/step - loss: 0.0109 - acc: 0.9980 - val_loss: 1.4258e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0093 - acc: 0.9987\n",
      "Epoch 20: val_loss improved from 0.00014 to 0.00007, saving model to models\\model.h5\n",
      "124/124 [==============================] - 6s 48ms/step - loss: 0.0093 - acc: 0.9987 - val_loss: 6.9293e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0299 - acc: 0.9922\n",
      "Epoch 21: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 3s 24ms/step - loss: 0.0299 - acc: 0.9922 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9946\n",
      "Epoch 22: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 0.0228 - acc: 0.9947 - val_loss: 4.1595e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9987\n",
      "Epoch 23: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.0119 - acc: 0.9987 - val_loss: 1.2981e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9977\n",
      "Epoch 24: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 3s 23ms/step - loss: 0.0092 - acc: 0.9977 - val_loss: 4.6091e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9954\n",
      "Epoch 25: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 0.0198 - acc: 0.9955 - val_loss: 0.0011 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9949\n",
      "Epoch 26: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.0207 - acc: 0.9944 - val_loss: 2.5129e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.9937\n",
      "Epoch 27: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 0.0192 - acc: 0.9937 - val_loss: 9.7761e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9868\n",
      "Epoch 28: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 4s 33ms/step - loss: 0.0500 - acc: 0.9869 - val_loss: 9.3477e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "123/124 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9916\n",
      "Epoch 29: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 0.0280 - acc: 0.9912 - val_loss: 5.7569e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.0224 - acc: 0.9947\n",
      "Epoch 30: val_loss did not improve from 0.00007\n",
      "124/124 [==============================] - 4s 28ms/step - loss: 0.0224 - acc: 0.9947 - val_loss: 1.6975e-04 - val_acc: 1.0000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# models 디렉토리가 없으면 생성\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
